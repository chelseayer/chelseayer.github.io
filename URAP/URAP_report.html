<!doctype html>
<html lang="en">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
    <link rel="stylesheet" href="style.css">

    <title>CS 184 Final Project Proposal</title>
  </head>
  <body>
    <header>
      <h4>URAP, Spring 2020</h4>
      <h4>Mouse-Free Assistive Technology</h4>
      <h4>Final Report</h4>
      <h5>Chelsea Ye</h5>
      <br>
    </header>

    <h4>Summary</h4>
    <p>As a URAP apprentice in the Mouse-Free Assistive Technology project this semester, I work in the hand tracking team with Raghav and Riddhi, with the goal of exploring various computer vision approaches in mouse velocity control. We have discussed Haar Cascade, Foreground Segmentation, and Optical Flow techniques, and I mainly investigated and implemented the Foreground Segmentation method.</p>

    <h4>Foreground Segmentation</h4>
    <p>Foreground Segmentation analyzes video sequences and separates foreground from background based on the pixels that have changed from frame to frame. In application to our project, this segmentation detects the hand by extracting the moving foreground and computes the hand velocity from the position changes.</p>

    <h4>Anti-Shake Position Filter</h4>
    <p>The primitive hand tracker built with Foreground Segmentation can output the foregroundâ€™s real-time velocity (in both x-axis and y-axis) but with quite some noise. Therefore I added a position filter to improve the performance: the hand positions from each frame are interpolated with the previous position by some weight to reduce the noise. The resulting tracked movement is much smoother than without the filter. </p>

    <h4>Thresholding on Foreground</h4>
    <p>When tested, the hand tracker with filter sometimes ran into instability issues: a sudden change in environment lighting would result in misclassifying a large part of the frame (or even a whole frame) as foreground. To address this problem, I added a foreground constraint to the tracker such that it filters out the frames when the area of detected foreground is changing significantly. The tracker should also predict the potential hand movement using previous velocity and positions and only search for foreground within such predicted area, instead of the whole frame. Both accuracy and speed of detection were improved after this thresholding implementation.</p>

    <h4>Result Demo</h4>

    <video width="600" controls>
      <source src="demo.mov" type="video/mp4">
    </video>
    <p>My hand tracker using Foreground Segmentation. Real-time velocity is recorded at the bottom-left of the frame.</p>

    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>
  </body>
</html>